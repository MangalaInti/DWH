Difference between ETL vs ELT
ETL : ETL stands for Extract Transform and Load, It is the techique used in DWH for exracting the data from
different source system and transforming the data which includes cleansing, standardizing date formats,
removing duplicates, applying business rules and load them into DWH
It is mostly used for structured data


Traditional DWH which will have predefined schema and structure, its schema on write. It supports structured data type
ETL is mostly used Analytical purpose. e.g OALP


ELT :
ELT (Extract, Load, Transform) is a data integration approach where data is first extracted from various source systems 
and loaded directly into the target system (Data Warehouse (DWH) or Data Lake (DL)) in its raw form. 
Since data is initially loaded as-is, transformations can be performed in stages on need basis
It is particularly suited for handling large volumes of raw data (such as log files, IoT data, or unstructured data) 
handling real-time or near-real-time  data processing needs.
It is schema on read  
ELT is widely used in cloud platforms due to their scalability and processing power. 




--Key differences between Delta Lake, Data Lake, Lakehouse, and OneLake.

1. Data Lake
A Data Lake is a centralized repository designed to store large volumes of raw, unstructured, semi-structured, and structured data at scale.

Key Features:

Stores data in its native format (e.g., JSON, Parquet, CSV, or images).
Ideal for big data analytics and machine learning.
Uses object storage systems (e.g., Amazon S3, Azure Blob, Google Cloud Storage).
Data can be ingested without upfront modeling or transformation (schema-on-read)

2. Delta Lake

Delta Lake is an open-source storage layer that builds on top of a data lake to provide enhanced features such as ACID transactions and schema enforcement.

Key Features:

Ensures data reliability and consistency (ACID transactions).
Adds versioning for time-travel capabilities (e.g., viewing historical data states).
Handles schema evolution, allowing flexibility as data changes.
Supports batch and streaming data processing simultaneously.

 3. Lakehouse

The Lakehouse is a hybrid data architecture that combines the best of data lakes and data warehouses into a single platform.

Key Features:

Provides data lake scalability and flexibility with data warehouse performance for analytics.
Supports structured, semi-structured, and unstructured data in one system.
Allows for real-time and batch processing.
Reduces data duplication by removing the need for separate storage layers for lakes and warehouses
4. OneLake

