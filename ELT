--Difference between ETL vs ELT
ETL (Extract, Transform, Load)  was traditional approach  where data is first extracted
from various sources systems, transformed into suitable format
and then loaded into DWH. This approach is more suitable for structured data and predefined schemas

ELT(Extract, Load, Transform)  emerged as a more flexible approach, particularly with advent of cloud DWH and Data lakes
In ELT data is first extracted from various source systems and loaded into data storage system (landing zone)
in its raw form. The transformation happens later leveraging the  processing power of modern DWH

--Benefits ELT system
  1. Real Time data processing - ELT simplifies the datapipelines, eliminating the staging areas
  2. Scalability & performance - ELT uses modern cloud based DWH for large scale data processing & transformation which
      results in faster processing and reduced latency.
  3. Flexibility - ELT allows more flexibility in data transformation
  4. 






--Addtional info on ETL
It is the techique used in DWH for exracting the data different source system and transforming 
the data which includes cleansing, standardizing date formats,
removing duplicates, applying business rules and load them into DWH
It is mostly used for structured data

Traditional DWH which will have predefined schema and structure, its schema on write. It supports structured data type
ETL is mostly used Analytical purpose. e.g OALP


ELT :
ELT (Extract, Load, Transform) is a data integration approach where data is first extracted from various source systems 
and loaded directly into the target system (Data Warehouse (DWH) or Data Lake (DL)) in its raw form. 
Since data is initially loaded as-is, transformations can be performed in stages on need basis
It is particularly suited for handling large volumes of raw data (such as log files, IoT data, or unstructured data) 
handling real-time or near-real-time  data processing needs.
It is schema on read  
ELT is widely used in cloud platforms due to their scalability and processing power. 




--Key differences between Delta Lake, Data Lake, Lakehouse, and OneLake.

1. Data Lake
A Data Lake is a centralized repository designed to store large volumes of raw, unstructured, 
semi-structured, and structured data at scale.

Key Features:

Stores data in its native format (e.g., JSON, Parquet, CSV, or images).
Ideal for big data analytics and machine learning.
Uses object storage systems (e.g., Amazon S3, Azure Blob, Google Cloud Storage).
Data can be ingested without upfront modeling or transformation (schema-on-read)

2. Delta Lake

Delta Lake is an open-source storage layer that builds on top of a data lake to 
provide enhanced features such as ACID transactions and schema enforcement.

Key Features:

Ensures data reliability and consistency (ACID transactions).
Adds versioning for time-travel capabilities (e.g., viewing historical data states).
Handles schema evolution, allowing flexibility as data changes.
Supports batch and streaming data processing simultaneously.

 3. Lakehouse

The Lakehouse is a hybrid data architecture that combines the best of data lakes and data warehouses 
into a single platform.

Key Features:

Provides data lake scalability and flexibility with data warehouse performance for analytics.
Supports structured, semi-structured, and unstructured data in one system.
Allows for real-time and batch processing.
Reduces data duplication by removing the need for separate storage layers for lakes and warehouses
4. OneLake

